{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29cef70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'G:\\Kashif_OpenEnded') \n",
    "from stlf_torch_kit import  DataLoadeing\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, time\n",
    "from stlf_torch_kit import univariate_multi_step\n",
    "from stlf_torch_kit import SaveBestModel, PlotLossCurves, LoadModel, train, TestModel, BatchGenerator, results\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc31f46",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b2a9dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6132, 29), (1752, 29), (876, 29))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path_dataset ='G:\\Kashif_OpenEnded\\Dataset'\n",
    "path_tr = os.path.join(path_dataset, 'CityLearn_train.csv')\n",
    "df_tr = pd.read_csv(path_tr)\n",
    "train_set = df_tr.iloc[:].values\n",
    "path_v = os.path.join(path_dataset, 'CityLearn_validation.csv')\n",
    "df_v = pd.read_csv(path_v)\n",
    "validation_set = df_v.iloc[:].values \n",
    "path_te = os.path.join(path_dataset, 'Citylearn_test.csv')\n",
    "df_te = pd.read_csv(path_te)\n",
    "test_set = df_te.iloc[:].values \n",
    "\n",
    "path_scaler = os.path.join(path_dataset, 'Scaler.pkl')\n",
    "scaler         = pickle.load(open(path_scaler, 'rb'))\n",
    "\n",
    "train_set.shape, validation_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "293ad9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Consumed 0.10862445831298828 sec\n"
     ]
    }
   ],
   "source": [
    "time_steps = 24\n",
    "target_len = 1 #how much steps do you wana forecast #Edit\n",
    "start = time.time()\n",
    "train_X , train_y = univariate_multi_step(train_set, time_steps, target_col=0,target_len=target_len)\n",
    "validation_X, validation_y = univariate_multi_step(validation_set, time_steps, target_col=0,target_len=target_len)\n",
    "test_X, test_y = univariate_multi_step(test_set, time_steps, target_col=0,target_len=target_len)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc241223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3989, 36, 21)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb52558d",
   "metadata": {},
   "source": [
    "#### Mostly Cited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1912c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOSTLY_CITED(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.lstm = nn.LSTM(29, 60, 3, batch_first=True, dropout=0.2).to(self.device)  # Added dropout\n",
    "        self.layer_norm = nn.LayerNorm(60).to(self.device)  # Added LayerNorm\n",
    "        self.fc = nn.Linear(60, 1).to(self.device)\n",
    "\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'weight_ih' in name or 'weight_hh' in name:\n",
    "                torch.nn.init.xavier_normal_(param.data)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.zeros_(param)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(3, x.size(0), 60).to(self.device)\n",
    "        c0 = torch.zeros(3, x.size(0), 60).to(self.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.layer_norm(out[:, -1, :])  # Apply LayerNorm\n",
    "        out = self.fc(out)  # Removed sigmoid activation\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bafbfa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOSTLY_CITED1(nn.Module):\n",
    "    def __init__(self, input_size=29, hidden_size=20, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        # Move all parameters to device\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Move input to same device as model\n",
    "        x = x.to(self.device)\n",
    "        out, _ = self.lstm(x)  # out shape: (batch, seq_len, hidden_size)\n",
    "        out = self.fc(out[:, -1, :])  # Take last timestep\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4659def4",
   "metadata": {},
   "source": [
    "# instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf1f740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MOSTLY_CITED1()#Edit\n",
    "criterion = nn.MSELoss() #Edit, don't change\n",
    "\n",
    "save_best_model = SaveBestModel()\n",
    "Plot_Loss=PlotLossCurves()\n",
    "load_model=LoadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096a217f",
   "metadata": {},
   "source": [
    "# Learning Rate & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9867523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr=0.001 # Edit\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=lr) #Edit\n",
    "lr = 0.001  # Initial learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)  # Added\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b55ecf",
   "metadata": {},
   "source": [
    "# Check Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53206b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cpu\n"
     ]
    }
   ],
   "source": [
    "def get_model_device(model):\n",
    "    return next(model.parameters()).device\n",
    "device = get_model_device(model)\n",
    "print(\"Model is on device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fafebb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aa963e",
   "metadata": {},
   "source": [
    "#### Path & other Stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3924df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 1\n",
    "num_epochs = 20 #Edit\n",
    "best_model_path=r'G:\\Kashif_OpenEnded\\chk'+str('\\\\') #Edit\n",
    "fig_path=r'G:\\Kashif_OpenEnded\\chk' #Edit\n",
    "train_data_loader, validation_data_loader, test_data_loader = DataLoadeing(train_X ,\n",
    "                                                                           train_y, \n",
    "                                                                           validation_X, \n",
    "                                                                           validation_y, \n",
    "                                                                           test_X, \n",
    "                                                                           test_y, \n",
    "                                                                           batch_size=32) #Batch_Size Edit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f460874b",
   "metadata": {},
   "source": [
    "#### Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b17e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss() # Edit, for Now Don't  Change\n",
    "\n",
    "criterion_mae = nn.L1Loss()\n",
    "\n",
    "save_best_model = SaveBestModel()\n",
    "Plot_Loss=PlotLossCurves()\n",
    "load_model=LoadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566bee91",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b37aa742",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Step [191/191], Training Loss: 0.0540\n",
      "Epoch [1/20], Step [54/54], Val Loss: 0.0402\n",
      "\n",
      "Saving best model for epoch: 1\n",
      " at G:\\Kashif_OpenEnded\\chk\\1best_model.pth\n",
      "Epoch [2/20], Step [191/191], Training Loss: 0.0401\n",
      "Epoch [2/20], Step [54/54], Val Loss: 0.0403\n",
      "Epoch [3/20], Step [191/191], Training Loss: 0.0383\n",
      "Epoch [3/20], Step [54/54], Val Loss: 0.0405\n",
      "Epoch [4/20], Step [191/191], Training Loss: 0.0370\n",
      "Epoch [4/20], Step [54/54], Val Loss: 0.0409\n",
      "Epoch [5/20], Step [191/191], Training Loss: 0.0360\n",
      "Epoch [5/20], Step [54/54], Val Loss: 0.0414\n",
      "Epoch [6/20], Step [191/191], Training Loss: 0.0350\n",
      "Epoch [6/20], Step [54/54], Val Loss: 0.0416\n",
      "Epoch [7/20], Step [191/191], Training Loss: 0.0340\n",
      "Epoch [7/20], Step [54/54], Val Loss: 0.0417\n",
      "Epoch [8/20], Step [191/191], Training Loss: 0.0327\n",
      "Epoch [8/20], Step [54/54], Val Loss: 0.0417\n",
      "Epoch [9/20], Step [191/191], Training Loss: 0.0314\n",
      "Epoch [9/20], Step [54/54], Val Loss: 0.0414\n",
      "Epoch [10/20], Step [191/191], Training Loss: 0.0298\n",
      "Epoch [10/20], Step [54/54], Val Loss: 0.0408\n",
      "Epoch [11/20], Step [191/191], Training Loss: 0.0282\n",
      "Epoch [11/20], Step [54/54], Val Loss: 0.0398\n",
      "\n",
      "Saving best model for epoch: 11\n",
      " at G:\\Kashif_OpenEnded\\chk\\11best_model.pth\n",
      "Epoch [12/20], Step [191/191], Training Loss: 0.0268\n",
      "Epoch [12/20], Step [54/54], Val Loss: 0.0383\n",
      "\n",
      "Saving best model for epoch: 12\n",
      " at G:\\Kashif_OpenEnded\\chk\\12best_model.pth\n",
      "Epoch [13/20], Step [191/191], Training Loss: 0.0256\n",
      "Epoch [13/20], Step [54/54], Val Loss: 0.0361\n",
      "\n",
      "Saving best model for epoch: 13\n",
      " at G:\\Kashif_OpenEnded\\chk\\13best_model.pth\n",
      "Epoch [14/20], Step [191/191], Training Loss: 0.0243\n",
      "Epoch [14/20], Step [54/54], Val Loss: 0.0339\n",
      "\n",
      "Saving best model for epoch: 14\n",
      " at G:\\Kashif_OpenEnded\\chk\\14best_model.pth\n",
      "Epoch [15/20], Step [191/191], Training Loss: 0.0233\n",
      "Epoch [15/20], Step [54/54], Val Loss: 0.0320\n",
      "\n",
      "Saving best model for epoch: 15\n",
      " at G:\\Kashif_OpenEnded\\chk\\15best_model.pth\n",
      "Epoch [16/20], Step [191/191], Training Loss: 0.0225\n",
      "Epoch [16/20], Step [54/54], Val Loss: 0.0305\n",
      "\n",
      "Saving best model for epoch: 16\n",
      " at G:\\Kashif_OpenEnded\\chk\\16best_model.pth\n",
      "Epoch [17/20], Step [191/191], Training Loss: 0.0219\n",
      "Epoch [17/20], Step [54/54], Val Loss: 0.0293\n",
      "\n",
      "Saving best model for epoch: 17\n",
      " at G:\\Kashif_OpenEnded\\chk\\17best_model.pth\n",
      "Epoch [18/20], Step [191/191], Training Loss: 0.0214\n",
      "Epoch [18/20], Step [54/54], Val Loss: 0.0284\n",
      "\n",
      "Saving best model for epoch: 18\n",
      " at G:\\Kashif_OpenEnded\\chk\\18best_model.pth\n",
      "Epoch [19/20], Step [191/191], Training Loss: 0.0211\n",
      "Epoch [19/20], Step [54/54], Val Loss: 0.0279\n",
      "\n",
      "Saving best model for epoch: 19\n",
      " at G:\\Kashif_OpenEnded\\chk\\19best_model.pth\n",
      "Epoch [20/20], Step [191/191], Training Loss: 0.0208\n",
      "Epoch [20/20], Step [54/54], Val Loss: 0.0276\n",
      "\n",
      "Saving best model for epoch: 20\n",
      " at G:\\Kashif_OpenEnded\\chk\\20best_model.pth\n",
      "Time Consumed 122.71890258789062 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train(start_epoch,\n",
    "      num_epochs,\n",
    "      best_model_path,\n",
    "      fig_path,\n",
    "      model,criterion,optimizer,save_best_model,Plot_Loss,\n",
    "      train_data_loader,\n",
    "      validation_data_loader)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ea015b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.666666666666668"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1240/60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c897f0",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8e071d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New lr = 0.001\n",
      "Time Consumed 0.1435375213623047 sec\n",
      "Mean Absolute Error (MAE): 0.38\n",
      "Median Absolute Error (MedAE): 0.29\n",
      "Mean Squared Error (MSE): 0.25\n",
      "Root Mean Squared Error (RMSE): 0.5\n",
      "Mean Absolute Percentage Error (MAPE): 61.16 %\n",
      "Median Absolute Percentage Error (MDAPE): 41.01 %\n",
      "\n",
      "\n",
      "y_test_unscaled.shape=  (851, 1)\n",
      "y_pred.shape=  (851, 1)\n"
     ]
    }
   ],
   "source": [
    "load_model_path=r'G:\\Kashif_OpenEnded\\chk\\20best_model.pth' # Edit\n",
    "test_model=TestModel()\n",
    "start = time.time()\n",
    "y_pred_scaled=test_model(model, test_X,load_model,load_model_path,lr)\n",
    "print('Time Consumed', time.time()-start, \"sec\")\n",
    "results(scaler, y_pred_scaled,test_y)\n",
    "\n",
    "# MAPE, MAE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293ff80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "STLF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
